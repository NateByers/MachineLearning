---
title: 'B529: Homework 4'
author: "Nathan Byers"
date: "Wednesday, April 21, 2015"
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancyhead[CO,CE]{B529 Machine Learning}
- \fancyfoot[CO,CE]{Source https://github.com/NateByers/MachineLearning/tree/master/Homework4}
- \fancyfoot[LE,RO]{\thepage}
output: pdf_document
---

# Question 1

For 2-dimensional data points, we define a kernel function $K(\mathbf{x}, \mathbf{x}’) = (1+\mathbf{x}^{T}x’)^{3}$, what is its corresponding transformation function $z = \Phi(x)$. (15 points)

# Answer 1

$$K(\mathbf{x'}, \mathbf{x})=(1+\mathbf{x}^{\textsc{t}}\mathbf{x'})^{3}=\left ( 1 + \begin{bmatrix}
x_{1} & x_{2}
\end{bmatrix} \begin{bmatrix}
x'_{1}\\ 
x'_{2}
\end{bmatrix}\right )^{3}$$

$$=(1 + x_{1}x'_{1}+x_{2}x'_{2})(1 + x_{1}x'_{1}+x_{2}x'_{2})(1 + x_{1}x'_{1}+x_{2}x'_{2})$$

$$=(1+2x_{1}{x'}_{1}+2x_{2}{x'}_{2}+x_{1}^{2}{x'}_{1}^{2}+2x_{1}{x'}_{1}x_{2}{x'}_{2}+x_{2}^{2}{x'}_{2}^{2})(1 + x_{1}x'_{1}+x_{2}x'_{2})$$

$$=1+3x_{1}{x'}_{1}+3x_{2}{x'}_{2}+3x_{1}^{2}{x'}_{1}^{2}+6x_{1}{x'}_{1}x_{2}{x'}_{2}+3x_{2}^{2}{x'}_{2}^{2}+x_{1}^{3}{x'}_{1}^{3}+3x_{1}^{2}{x'}_{1}^2x_{2}{x'}_{2}+3x_{1}{x'}_{1}x_{2}^{2}{x'}_{2}^{2}+x_{2}^{3}{x'}_{2}^{3}$$

$$\Phi(\mathbf{x})^{\textsc{t}}\Phi(\mathbf{x})=\begin{bmatrix}
1 & \sqrt{3}x_{1} & \sqrt{3}x_{2} & \sqrt{3}x_{1}^{2} & \sqrt{6}x_{1}x_{2} & \sqrt{3}x_{2}^{2} & x_{1}^3 & \sqrt{3}x_{1}^{2}x_{2} & \sqrt{3}x_{1}x_{2}^{2} & x_{2}^{3}
\end{bmatrix}
\begin{bmatrix}
1 \\
\sqrt{3}{x'}_{1} \\
\sqrt{3}{x'}_{2} \\
\sqrt{3}{x'}_{1}^{2} \\
\sqrt{6}{x'}_{1}{x'}_{2} \\
\sqrt{3}{x'}_{2}^{2} \\
{x'}_{1}^3 \\
\sqrt{3}{x'}_{1}^{2}{x'}_{2} \\
\sqrt{3}{x'}_{1}{x'}_{2}^{2} \\
{x'}_{2}^{3}
\end{bmatrix}$$


# Question 2

In the following Hidden Markov model, the observation sequence is TTHH. If the hidden path is BBFF, what is the probability that the sequence is generated by the path BBFF (10 points). If the hidden path is unknown, generate the graph for the decoding problem (15 points). What is the heaviest path in the graph? (10 points)

![hiddenMarkov](images/hiddenMarkov.png)

# Answer 2

The probabilities of getting a heads or tails, given that it's a fair or biased coin, are:
$$P(H|F)=P(T|F)=0.5, P(H|B)= 0.75, P(T|B) = 0.25$$

The transition probabilities are:
$$a_{\textsc{FF}}=a_{\textsc{BB}}=0.7, a_{\textsc{BF}}=a_{\textsc{FB}}=0.3$$

The probability that the fair/biased sequence BBFF would give a coin flip sequence TTHH is:
$$P(\mathbf{x}=TTHH|\mathbf{\pi}=BBFF)=(0.5\times 0.25)(0.7\times 0.25)(0.3\times 0.5)(0.7 \times 0.5)=0.00115$$

I use the `diagram` package to draw the graph in R.

```{r, message=FALSE}
library(diagram)
# set margins
par(mar = c(1, 1, 1, 1))
# open a plotting region
openplotmat()
# first argument of coordinates() specifies the number of elements in each row
elpos <- coordinates (c(1, rep(2, 4)))
# create data.frame say from what position to where
from <- rep(1:7, each = 2)
to <- c(2:3, rep(4:5, 2), rep(6:7, 2), rep(8:9, 2))
arrpos <- matrix(ncol = 2, nrow = length(from))

# draw arrows
for(i in 1:length(from)){
  arrpos[i, ] <- straightarrow(to = elpos[to[i], ], from = elpos[from[i], ],
                lwd = 2, arr.pos = 0.6, arr.length = 0.5, endhead = FALSE)
}

# draw circles
flip <- rep(c("T", "H"), each = 4)
pi <- rep(c("B", "F"), 4)
textellipse(elpos[1,], .05, lab = "start", shadow.size = 0)
for(i in 1:(length(flip))) {
  textellipse(elpos[i + 1,], 0.05, lab = paste(flip[i], pi[i], sep = ", "))
}

```

Here I redraw with the probabilities at each state, and add the transition probabilities for the arrows.

```{r}
openplotmat()

# draw arrows
for(i in 1:length(from)){
  straightarrow(to = elpos[to[i], ], from = elpos[from[i], ],
                               lwd = 2, arr.pos = 0.6, arr.length = 0.5, endhead = FALSE)
}

# draw circles
prob <- sapply(1:length(flip), function(i){
  state <- paste(flip[i], pi[i])
  if(state == "T B"){
    .25
  }else if(state == "H B"){
    .75
  }else{
    .5
  }
})
textellipse(elpos[1,], .05, lab = "start", shadow.size = 0)
for(i in 1:(length(flip))) {
  textellipse(elpos[i + 1,], 0.05, lab = prob[i])
}

pi_prob <- c(.5, .5, rep(c(.7, .3, .3, .7), 3))

# draw transition probabilities
for(i in 1:12){
  if((i %% 2) == 0){
    text(arrpos[i, 1] - 0.05, arrpos[i, 2], pi_prob[i])
  }else{
    text(arrpos[i, 1] + 0.05, arrpos[i, 2], pi_prob[i])
  }
  
}
```

Below is the heaviest edge.

```{r}
openplotmat()
edge <- c(2, 6, 9, 11)
# draw arrows
for(i in 1:length(from)){
  if(i %in% edge){col <- "red"}else{col <- "black"}
  straightarrow(to = elpos[to[i], ], from = elpos[from[i], ], lcol = col,
                lwd = 2, arr.pos = 0.6, arr.length = 0.5, endhead = FALSE)
}

textellipse(elpos[1,], .05, lab = "start", shadow.size = 0)
for(i in 1:(length(flip))) {
  textellipse(elpos[i + 1,], 0.05, lab = paste(flip[i], pi[i], sep = ", "))
}

```

# Question 3

Using the following data set for credit card application, compute the mutual information for each feature (15 points), compute the chi-square value for each feature (15 points)  

![table](images/table.png)

# Question 4

Given a 2-dimensional data set (0,1) (2,3), (3,4), (2,4), (4,6). Please use R to find two resulting vectors in PCA and plot the data points and the vectors (20 points).   

# Answer 4